{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jm6B9mTuqGmf"
   },
   "source": [
    "<div id=\"image\">\n",
    "<img src=\"https://www.imt-atlantique.fr/sites/default/files/logo_mt_0_0.png\" WIDTH=280 HEIGHT=280>\n",
    "</div>\n",
    "<div id=\"subject\">\n",
    "<CENTER>\n",
    "</br>\n",
    "\n",
    "\n",
    "<font size=\"5\"></br> UE Introduction au Machine Learning: Project ML </font></br></div>\n",
    "</CENTER>\n",
    "<CENTER>\n",
    "<font size=\"3\"></br></font></br></div>\n",
    "</CENTER>\n",
    "<CENTER>\n",
    "<span style=\"color:blue\"></span>\n",
    "</CENTER>\n",
    "\n",
    "The objective of the project is to apply a Machine Learning model onto two different datasets:\n",
    "- Banknote Authentication Dataset\n",
    "- Chronic Kidney Disease:\n",
    "\n",
    "Workflow : \n",
    "\n",
    "1. Import the dataset\n",
    "2. Clean the data, perform pre-processing\n",
    "I Replace missing values by average or median values\n",
    "I Center and normalize the data\n",
    "3. Split the dataset\n",
    "I Split between training set and test set\n",
    "I Split the training set for cross-validation\n",
    "4. Train the model (including feature selection)\n",
    "5. Validate the model\n",
    "Objective: collaboratively implement this workflow and apply it to different ML problems/datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2Trc7GWqGm4"
   },
   "source": [
    "# Import Data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T17:52:04.758116Z",
     "start_time": "2020-11-28T17:52:04.276122Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "NCRwh9bOxR0k",
    "outputId": "aa87a609-7df6-458e-d1a3-25c3f84f6354"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pylab import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Informations sur l'ensemble des données :\n",
    "\n",
    "Les données ont été extraites d'images prises sur des spécimens de billets de banque authentiques et contrefaits. Pour la numérisation, une caméra industrielle habituellement utilisée pour l'inspection des imprimés a été utilisée. Les images finales ont 400x 400 pixels. En raison de l'objectif de l'objet et de la distance de l'objet étudié, des images en échelle de gris avec une résolution d'environ 660 dpi ont été obtenues. L'outil de transformation en ondelettes a été utilisé pour extraire les caractéristiques des images. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance of WTI</th>\n",
       "      <th>Skewness of WTI</th>\n",
       "      <th>Curtosis of WTI</th>\n",
       "      <th>Entropy of image</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.433735</td>\n",
       "      <td>1.922353</td>\n",
       "      <td>1.397627</td>\n",
       "      <td>-1.191657</td>\n",
       "      <td>0.444606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.842763</td>\n",
       "      <td>5.869047</td>\n",
       "      <td>4.310030</td>\n",
       "      <td>2.101013</td>\n",
       "      <td>0.497103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.042100</td>\n",
       "      <td>-13.773100</td>\n",
       "      <td>-5.286100</td>\n",
       "      <td>-8.548200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.773000</td>\n",
       "      <td>-1.708200</td>\n",
       "      <td>-1.574975</td>\n",
       "      <td>-2.413450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.496180</td>\n",
       "      <td>2.319650</td>\n",
       "      <td>0.616630</td>\n",
       "      <td>-0.586650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.821475</td>\n",
       "      <td>6.814625</td>\n",
       "      <td>3.179250</td>\n",
       "      <td>0.394810</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.824800</td>\n",
       "      <td>12.951600</td>\n",
       "      <td>17.927400</td>\n",
       "      <td>2.449500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Variance of WTI  Skewness of WTI  Curtosis of WTI  Entropy of image  \\\n",
       "count      1372.000000      1372.000000      1372.000000       1372.000000   \n",
       "mean          0.433735         1.922353         1.397627         -1.191657   \n",
       "std           2.842763         5.869047         4.310030          2.101013   \n",
       "min          -7.042100       -13.773100        -5.286100         -8.548200   \n",
       "25%          -1.773000        -1.708200        -1.574975         -2.413450   \n",
       "50%           0.496180         2.319650         0.616630         -0.586650   \n",
       "75%           2.821475         6.814625         3.179250          0.394810   \n",
       "max           6.824800        12.951600        17.927400          2.449500   \n",
       "\n",
       "             Class  \n",
       "count  1372.000000  \n",
       "mean      0.444606  \n",
       "std       0.497103  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/cleme/OneDrive/Documents/MCE - Machine Learning/Project ML/data_banknote_authentication.txt', sep=\",\", header=None)\n",
    "data.columns = [\"Variance of WTI\",\"Skewness of WTI\",\"Curtosis of WTI\",\"Entropy of image\",\"Class\"]\n",
    "data.describe()\n",
    "\n",
    "#1. variance de l'image transformée en ondelettes\n",
    "#2. asymétrie de l'image transformée en ondelettes\n",
    "#3. applatissement de l'image transformée en ondelettes \n",
    "# 4. entropie de l'image \n",
    "# 5. classe (nombre entier)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "var, skew, kurt, entropy, label =data['Variance of WTI'], data['Skewness of WTI'], data['Curtosis of WTI'], data['Entropy of image'], data['Class']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "206-PpLNjEZQ"
   },
   "source": [
    "1) You should first clean the dataset (handle missing values and  categorical values) and especially : \n",
    "- Replace missing values by average or median values\n",
    "- Center and normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_NaN(data):\n",
    "    countNaN = np.zeros((np.shape(data)[1]))\n",
    "    for k in data:\n",
    "        for i in range (len(data[k])):\n",
    "            va_k = data[k]\n",
    "            if va_k[i] == np.NaN:\n",
    "                countNaN[k] += 1\n",
    "    return countNaN\n",
    "\n",
    "count_NaN(data)\n",
    "\n",
    "#Pas de Nan dans le premier dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance of WTI</th>\n",
       "      <th>Skewness of WTI</th>\n",
       "      <th>Curtosis of WTI</th>\n",
       "      <th>Entropy of image</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.433735</td>\n",
       "      <td>1.922353</td>\n",
       "      <td>1.397627</td>\n",
       "      <td>-1.191657</td>\n",
       "      <td>0.444606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.842763</td>\n",
       "      <td>5.869047</td>\n",
       "      <td>4.310030</td>\n",
       "      <td>2.101013</td>\n",
       "      <td>0.497103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.042100</td>\n",
       "      <td>-13.773100</td>\n",
       "      <td>-5.286100</td>\n",
       "      <td>-8.548200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.773000</td>\n",
       "      <td>-1.708200</td>\n",
       "      <td>-1.574975</td>\n",
       "      <td>-2.413450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.496180</td>\n",
       "      <td>2.319650</td>\n",
       "      <td>0.616630</td>\n",
       "      <td>-0.586650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.821475</td>\n",
       "      <td>6.814625</td>\n",
       "      <td>3.179250</td>\n",
       "      <td>0.394810</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.824800</td>\n",
       "      <td>12.951600</td>\n",
       "      <td>17.927400</td>\n",
       "      <td>2.449500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Variance of WTI  Skewness of WTI  Curtosis of WTI  Entropy of image  \\\n",
       "count      1372.000000      1372.000000      1372.000000       1372.000000   \n",
       "mean          0.433735         1.922353         1.397627         -1.191657   \n",
       "std           2.842763         5.869047         4.310030          2.101013   \n",
       "min          -7.042100       -13.773100        -5.286100         -8.548200   \n",
       "25%          -1.773000        -1.708200        -1.574975         -2.413450   \n",
       "50%           0.496180         2.319650         0.616630         -0.586650   \n",
       "75%           2.821475         6.814625         3.179250          0.394810   \n",
       "max           6.824800        12.951600        17.927400          2.449500   \n",
       "\n",
       "             Class  \n",
       "count  1372.000000  \n",
       "mean      0.444606  \n",
       "std       0.497103  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_NaN(data):\n",
    "    no_NaN_data = data\n",
    "    mean_data = np.mean(data)\n",
    "    count_replaced_values = np.zeros((np.shape(data)[1]))\n",
    "    for k in data:\n",
    "        for i in range (len(data[k])):\n",
    "            va_k = no_NaN_data[k]\n",
    "            if va_k[i] == np.NaN:\n",
    "                count_replaced_values[k] += 1\n",
    "                va_k[i] = mean_data[k] #replace with mean\n",
    "    return no_NaN_data, count_replaced_values\n",
    "\n",
    "replace_NaN(data)[0].describe()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance of WTI</th>\n",
       "      <th>Skewness of WTI</th>\n",
       "      <th>Curtosis of WTI</th>\n",
       "      <th>Entropy of image</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.372000e+03</td>\n",
       "      <td>1.372000e+03</td>\n",
       "      <td>1.372000e+03</td>\n",
       "      <td>1.372000e+03</td>\n",
       "      <td>1372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.678625e-16</td>\n",
       "      <td>-3.509098e-16</td>\n",
       "      <td>-2.531584e-16</td>\n",
       "      <td>-3.680244e-16</td>\n",
       "      <td>0.444606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000365e+00</td>\n",
       "      <td>1.000365e+00</td>\n",
       "      <td>1.000365e+00</td>\n",
       "      <td>1.000365e+00</td>\n",
       "      <td>0.497103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.630737e+00</td>\n",
       "      <td>-2.675252e+00</td>\n",
       "      <td>-1.551303e+00</td>\n",
       "      <td>-3.502703e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.765474e-01</td>\n",
       "      <td>-6.188189e-01</td>\n",
       "      <td>-6.899455e-01</td>\n",
       "      <td>-5.817379e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.197423e-02</td>\n",
       "      <td>6.771828e-02</td>\n",
       "      <td>-1.812706e-01</td>\n",
       "      <td>2.880644e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.402427e-01</td>\n",
       "      <td>8.338757e-01</td>\n",
       "      <td>4.135174e-01</td>\n",
       "      <td>7.553713e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.249008e+00</td>\n",
       "      <td>1.879908e+00</td>\n",
       "      <td>3.836586e+00</td>\n",
       "      <td>1.733680e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Variance of WTI  Skewness of WTI  Curtosis of WTI  Entropy of image  \\\n",
       "count     1.372000e+03     1.372000e+03     1.372000e+03      1.372000e+03   \n",
       "mean      3.678625e-16    -3.509098e-16    -2.531584e-16     -3.680244e-16   \n",
       "std       1.000365e+00     1.000365e+00     1.000365e+00      1.000365e+00   \n",
       "min      -2.630737e+00    -2.675252e+00    -1.551303e+00     -3.502703e+00   \n",
       "25%      -7.765474e-01    -6.188189e-01    -6.899455e-01     -5.817379e-01   \n",
       "50%       2.197423e-02     6.771828e-02    -1.812706e-01      2.880644e-01   \n",
       "75%       8.402427e-01     8.338757e-01     4.135174e-01      7.553713e-01   \n",
       "max       2.249008e+00     1.879908e+00     3.836586e+00      1.733680e+00   \n",
       "\n",
       "             Class  \n",
       "count  1372.000000  \n",
       "mean      0.444606  \n",
       "std       0.497103  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In practice we often ignore the shape of the distribution and just transform the data to center it by removing \n",
    "# the mean value of each feature, then scale it by dividing non-constant features by their standard deviation.\n",
    "\n",
    "def center_and_normalize(data):\n",
    "    center_and_normalize = data\n",
    "    mean_data, std_data = np.mean(data), np.std(data)\n",
    "    types_data = data.dtypes\n",
    "    for k in center_and_normalize:\n",
    "        if types_data[k] == float: #on se souhaite pas centrée réduire les labels\n",
    "            center_and_normalize[k] = (center_and_normalize[k] - mean_data[k])*(1/std_data[k])\n",
    "    return center_and_normalize\n",
    "\n",
    "\n",
    "center_and_normalize(data).describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Split the dataset : \n",
    "- Split between training set and test set\n",
    "- Split the training set for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance of WTI</th>\n",
       "      <th>Skewness of WTI</th>\n",
       "      <th>Curtosis of WTI</th>\n",
       "      <th>Entropy of image</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.372000e+03</td>\n",
       "      <td>1.372000e+03</td>\n",
       "      <td>1.372000e+03</td>\n",
       "      <td>1.372000e+03</td>\n",
       "      <td>1372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.301366e-16</td>\n",
       "      <td>-2.338589e-17</td>\n",
       "      <td>-1.047915e-17</td>\n",
       "      <td>3.042594e-17</td>\n",
       "      <td>0.444606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000365e+00</td>\n",
       "      <td>1.000365e+00</td>\n",
       "      <td>1.000365e+00</td>\n",
       "      <td>1.000365e+00</td>\n",
       "      <td>0.497103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.630737e+00</td>\n",
       "      <td>-2.675252e+00</td>\n",
       "      <td>-1.551303e+00</td>\n",
       "      <td>-3.502703e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.765474e-01</td>\n",
       "      <td>-6.188189e-01</td>\n",
       "      <td>-6.899455e-01</td>\n",
       "      <td>-5.817379e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.197423e-02</td>\n",
       "      <td>6.771828e-02</td>\n",
       "      <td>-1.812706e-01</td>\n",
       "      <td>2.880644e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.402427e-01</td>\n",
       "      <td>8.338757e-01</td>\n",
       "      <td>4.135174e-01</td>\n",
       "      <td>7.553713e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.249008e+00</td>\n",
       "      <td>1.879908e+00</td>\n",
       "      <td>3.836586e+00</td>\n",
       "      <td>1.733680e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Variance of WTI  Skewness of WTI  Curtosis of WTI  Entropy of image  \\\n",
       "count     1.372000e+03     1.372000e+03     1.372000e+03      1.372000e+03   \n",
       "mean     -2.301366e-16    -2.338589e-17    -1.047915e-17      3.042594e-17   \n",
       "std       1.000365e+00     1.000365e+00     1.000365e+00      1.000365e+00   \n",
       "min      -2.630737e+00    -2.675252e+00    -1.551303e+00     -3.502703e+00   \n",
       "25%      -7.765474e-01    -6.188189e-01    -6.899455e-01     -5.817379e-01   \n",
       "50%       2.197423e-02     6.771828e-02    -1.812706e-01      2.880644e-01   \n",
       "75%       8.402427e-01     8.338757e-01     4.135174e-01      7.553713e-01   \n",
       "max       2.249008e+00     1.879908e+00     3.836586e+00      1.733680e+00   \n",
       "\n",
       "             Class  \n",
       "count  1372.000000  \n",
       "mean      0.444606  \n",
       "std       0.497103  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = replace_NaN(data)[0]\n",
    "clean_data = center_and_normalize(clean_data)\n",
    "\n",
    "clean_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Faire aussi cross validation\n",
    "\n",
    "def split_data(data, test_size):\n",
    "    labels = data.iloc[:,-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=test_size)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.149455\n",
       "1       1.064453\n",
       "2      -0.777352\n",
       "3       1.295478\n",
       "4      -1.087038\n",
       "          ...   \n",
       "1367   -0.097693\n",
       "1368   -1.158984\n",
       "1369   -2.621646\n",
       "1370   -1.756471\n",
       "1371   -0.439822\n",
       "Name: Skewness of WTI, Length: 1372, dtype: float64"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for k in data:\n",
    "#         shapiro_test = shapiro(data[k])\n",
    "#         A = shapiro_test.pvalue\n",
    "# A\n",
    "# len(data)\n",
    "data.iloc[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may implement feature selection: bruteforce, by looking at correlations, from an ACP (for classiffication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-288-a6b3e57652f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata_reduc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mpca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-288-a6b3e57652f0>\u001b[0m in \u001b[0;36mpca\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mdata_reduc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata_reduc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "#Assumption to check --> Data are gaussian distributed --> check with Shapiro Test\n",
    "\n",
    "#En statistique, le test de Shapiro–Wilk teste l'hypothèse nulle selon laquelle un échantillon x 1 , … , x n \n",
    "#est issu d'une population normalement distribuée. \n",
    "\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def shapiro_test(data):\n",
    "    n = np.shape(data)[1]\n",
    "    p_values = np.zeros((n))\n",
    "    for k in range(n):\n",
    "        data_k = data.iloc[:,k]\n",
    "        shapiro_test = shapiro(data_k)\n",
    "        p_values[k] = shapiro_test.pvalue\n",
    "    return p_values\n",
    "\n",
    "shapiro_test(clean_data)\n",
    "\n",
    "\n",
    "def pca(data):\n",
    "    pca = PCA.fit(data)\n",
    "    data_reduc = pca.transform(data)\n",
    "    return data_reduc\n",
    "\n",
    "pca(clean_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PCA_lab_session_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
